{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Week_4_1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willystumblr/AI-ML_Team_5/blob/kms/Week4/NLP_Week_4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7xza8Y-hgjO"
      },
      "source": [
        "**Note:** This notebook can run using TensorFlow 2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt3s1mqihgjP"
      },
      "source": [
        "#!pip install tensorflow==2.5.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5889c2-f321-4caf-952e-c4537ae0fac9"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
            "263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2Wxg2CzpxtD"
      },
      "source": [
        "# Terms\n",
        "* corpus: dataset을 NLP에서 지칭하는 말\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4m-N4b9XQH9",
        "outputId": "0bab296e-42d9-4edc-abe2-48e81582fe2b"
      },
      "source": [
        "print(xs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0   0   4]\n",
            " [  0   0   0 ...   0   4   2]\n",
            " [  0   0   0 ...   4   2  66]\n",
            " ...\n",
            " [  0   0   0 ...  61  60 262]\n",
            " [  0   0   0 ...  60 262  13]\n",
            " [  0   0   0 ... 262  13   9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5_q4W5XVUrP"
      },
      "source": [
        "# Looking into codes\n",
        "* `xs, labels = input_sequences[:, :-1]`: It is list indexing, it returns all elements `[:]` except the last one -1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdPm5XlqqV61"
      },
      "source": [
        "# N-gram 언어 모델\n",
        "n-gram 언어 모델은 여전히 카운트에 기반한 통계적 접근을 사용하고 있으므로 SLM의 일종입니다. 다만, 이전에 등장한 모든 단어를 고려하는 것이 아니라 일부 단어만 고려하는 접근 방법을 사용합니다. 그리고 이때 일부 단어를 몇 개 보느냐를 결정하는데 이것이 n-gram에서의 n이 가지는 의미입니다.\n",
        "\n",
        "SLM의 한계는 훈련 코퍼스에 확률을 계산하고 싶은 문장이나 단어가 없을 수 있다는 점입니다. 그리고 확률을 계산하고 싶은 문장이 길어질수록 갖고있는 코퍼스에서 그 문장이 존재하지 않을 가능성이 높습니다. 다시 말하면 카운트할 수 없을 가능성이 높습니다. 그런데 다음과 같이 참고하는 단어들을 줄이면 카운트를 할 수 있을 가능성이 높일 수 있습니다.\n",
        "\n",
        "𝑃(is|An adorable little boy) ≈ 𝑃(is|little boy)\n",
        "\n",
        "즉, 앞에서는 An adorable little boy가 나왔을 때 is가 나올 확률을 구하기 위해서는 An adorable little boy가 나온 횟수와 An adorable little boy is가 나온 횟수를 카운트해야만 했지만, **이제는 단어의 확률을 구하고자 기준 단어의 앞 단어를 전부 포함해서 카운트하는 것이 아니라, 앞 단어 중 임의의 개수만 포함해서 카운트하여 근사하자는 것입니다.** 이렇게 하면 갖고 있는 코퍼스에서 해당 단어의 시퀀스를 카운트할 확률이 높아집니다.\n",
        "\n",
        "이때 임의의 개수를 정하기 위한 기준을 위해 사용하는 것이 n-gram입니다. n-gram은 n개의 연속적인 단어 나열을 의미합니다. 갖고 있는 코퍼스에서 n개의 단어 뭉치 단위로 끊어서 이를 하나의 토큰으로 간주합니다. 예를 들어서 문장 An adorable little boy is spreading smiles이 있을 때, 각 n에 대해서 n-gram을 전부 구해보면 다음과 같습니다.\n",
        "* **unigrams** : an, adorable, little, boy, is, spreading, smiles\n",
        "* **bigrams** : an adorable, adorable little, little boy, boy is, is spreading, spreading smiles\n",
        "* **trigrams** : an adorable little, adorable little boy, little boy is, boy is spreading, is spreading smiles\n",
        "* **4-grams** : an adorable little boy, adorable little boy is, little boy is spreading, boy is spreading smiles\n",
        "\n",
        "n-gram을 통한 언어 모델에서는 다음에 나올 단어의 예측은 오직 n-1개의 단어에만 의존합니다. 예를 들어 'An adorable little boy is spreading' 다음에 나올 단어를 예측하고 싶다고 할 때, n=4라고 한 4-gram을 이용한 언어 모델을 사용한다고 합시다. 이 경우, spreading 다음에 올 단어를 예측하는 것은 n-1에 해당되는 앞의 3개의 단어만을 고려합니다.\n",
        "\n",
        "![image.png](https://wikidocs.net/images/page/21692/n-gram.PNG)\n",
        "\n",
        "출처: [여기](https://wikidocs.net/21692)\n",
        "\n",
        "# `tf.keras.utils.to_categorical`\n",
        "1. use\n",
        "```\n",
        "tf.keras.utils.to_categorical(\n",
        "    y, num_classes=None, dtype='float32'\n",
        ")\n",
        "```\n",
        "2. role\n",
        "- Converts a class vector (integers) to binary class matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJtwVB2NbOAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50759a76-83ab-4648-d6e3-6c98e05c5f99"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])\n",
        "print(tokenizer.word_index['cheeks'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Cv68JOakwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4eb80e-c002-4148-f37f-97617e25fbf3"
      },
      "source": [
        "print(xs[6])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY-jwvfgbEF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba24a60b-6c6d-4c25-b578-5a17f009a308"
      },
      "source": [
        "print(ys[6])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY7IuRoTTqLu"
      },
      "source": [
        "# One-hot encoding\n",
        "원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식입니다. 이렇게 표현된 벡터를 원-핫 벡터(One-Hot vector)라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtzlUMYadhKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6bfac6c-5f3d-4f45-99ba-7218478a6d0d"
      },
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  4  2 66  8 67 68]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4myRpB1c4Gg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58a8fa1-6a20-4306-dde2-e3dd3fadc3f7"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de26ddd-540b-4b21-da38-d74151033af3"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=1)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 4s 10ms/step - loss: 5.5676 - accuracy: 0.0155\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.5406 - accuracy: 0.0574\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.4831 - accuracy: 0.0419\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.3371 - accuracy: 0.0331\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.1424 - accuracy: 0.0397\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.0706 - accuracy: 0.0442\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.0312 - accuracy: 0.0596\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.9932 - accuracy: 0.0508\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.9623 - accuracy: 0.0508\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.9241 - accuracy: 0.0662\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.8843 - accuracy: 0.0618\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 4.8383 - accuracy: 0.0662\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.7847 - accuracy: 0.0684\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.7304 - accuracy: 0.0662\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.6739 - accuracy: 0.0773\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.6156 - accuracy: 0.0751\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.5544 - accuracy: 0.0795\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.4920 - accuracy: 0.0883\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.4366 - accuracy: 0.1015\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.3834 - accuracy: 0.1060\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.3406 - accuracy: 0.1126\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.2865 - accuracy: 0.1236\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2420 - accuracy: 0.1280\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2051 - accuracy: 0.1280\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.1513 - accuracy: 0.1325\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.1081 - accuracy: 0.1479\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.0650 - accuracy: 0.1457\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.0269 - accuracy: 0.1567\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.9727 - accuracy: 0.1744\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.9256 - accuracy: 0.1788\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.8863 - accuracy: 0.1987\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.8439 - accuracy: 0.2009\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.8042 - accuracy: 0.2274\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.7585 - accuracy: 0.2185\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.7176 - accuracy: 0.2384\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.6697 - accuracy: 0.2450\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 3.6292 - accuracy: 0.2472\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.5841 - accuracy: 0.2517\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.5569 - accuracy: 0.2539\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.5186 - accuracy: 0.2715\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.4684 - accuracy: 0.2826\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.4272 - accuracy: 0.2781\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.3818 - accuracy: 0.2914\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.3327 - accuracy: 0.3002\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.2933 - accuracy: 0.3179\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.2519 - accuracy: 0.3157\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.2267 - accuracy: 0.3201\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.1949 - accuracy: 0.3400\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.1584 - accuracy: 0.3488\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.1214 - accuracy: 0.3510\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.0813 - accuracy: 0.3664\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.0379 - accuracy: 0.3863\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.0016 - accuracy: 0.3951\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.9734 - accuracy: 0.3885\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.9512 - accuracy: 0.3951\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.9400 - accuracy: 0.3929\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.8879 - accuracy: 0.4062\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.8474 - accuracy: 0.4040\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.8154 - accuracy: 0.4172\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.7834 - accuracy: 0.4327\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.7514 - accuracy: 0.4393\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.7326 - accuracy: 0.4415\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.6901 - accuracy: 0.4525\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.6585 - accuracy: 0.4658\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.6299 - accuracy: 0.4614\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.5938 - accuracy: 0.4812\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.5671 - accuracy: 0.4945\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.5456 - accuracy: 0.5121\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.5107 - accuracy: 0.5298\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4859 - accuracy: 0.5232\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4554 - accuracy: 0.5364\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4362 - accuracy: 0.5276\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4352 - accuracy: 0.5408\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4162 - accuracy: 0.5320\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3691 - accuracy: 0.5430\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3400 - accuracy: 0.5563\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3056 - accuracy: 0.5607\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2798 - accuracy: 0.5585\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2573 - accuracy: 0.5453\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2411 - accuracy: 0.5563\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2203 - accuracy: 0.5695\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2020 - accuracy: 0.5740\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1701 - accuracy: 0.5982\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1501 - accuracy: 0.5938\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1246 - accuracy: 0.6026\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.1032 - accuracy: 0.6093\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0876 - accuracy: 0.6137\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0622 - accuracy: 0.6071\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0419 - accuracy: 0.6203\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0177 - accuracy: 0.6115\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0078 - accuracy: 0.6358\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9933 - accuracy: 0.6446\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9623 - accuracy: 0.6446\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9401 - accuracy: 0.6534\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9121 - accuracy: 0.6755\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8930 - accuracy: 0.6667\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8759 - accuracy: 0.6689\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.8563 - accuracy: 0.6799\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8417 - accuracy: 0.6843\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8202 - accuracy: 0.6954\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8008 - accuracy: 0.6909\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8163 - accuracy: 0.6821\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7821 - accuracy: 0.6909\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.7472 - accuracy: 0.7020\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.7363 - accuracy: 0.7064\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7189 - accuracy: 0.7064\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6981 - accuracy: 0.7174\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6748 - accuracy: 0.7174\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6690 - accuracy: 0.7285\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6433 - accuracy: 0.7329\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.6254 - accuracy: 0.7439\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6082 - accuracy: 0.7461\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5905 - accuracy: 0.7506\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5734 - accuracy: 0.7506\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5568 - accuracy: 0.7594\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5397 - accuracy: 0.7770\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.5254 - accuracy: 0.7682\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5117 - accuracy: 0.7682\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4946 - accuracy: 0.7704\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4798 - accuracy: 0.7748\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4630 - accuracy: 0.7815\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4520 - accuracy: 0.7770\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4334 - accuracy: 0.7903\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4195 - accuracy: 0.7881\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4059 - accuracy: 0.7969\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3898 - accuracy: 0.7947\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3734 - accuracy: 0.7947\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3630 - accuracy: 0.7925\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3722 - accuracy: 0.7947\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3510 - accuracy: 0.7903\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3809 - accuracy: 0.7770\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3284 - accuracy: 0.7881\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3110 - accuracy: 0.7969\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3018 - accuracy: 0.8057\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.2900 - accuracy: 0.8013\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2737 - accuracy: 0.8013\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.2686 - accuracy: 0.7969\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2555 - accuracy: 0.8146\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2376 - accuracy: 0.8256\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2306 - accuracy: 0.8190\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2056 - accuracy: 0.8300\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1876 - accuracy: 0.8322\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.2037 - accuracy: 0.8256\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3142 - accuracy: 0.7881\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3180 - accuracy: 0.7837\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3076 - accuracy: 0.7660\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2607 - accuracy: 0.7792\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2206 - accuracy: 0.7991\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.1939 - accuracy: 0.8057\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1735 - accuracy: 0.8079\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2009 - accuracy: 0.8013\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1748 - accuracy: 0.8190\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1485 - accuracy: 0.8278\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1307 - accuracy: 0.8278\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.1169 - accuracy: 0.8300\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.0949 - accuracy: 0.8344\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0886 - accuracy: 0.8389\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0682 - accuracy: 0.8322\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.0638 - accuracy: 0.8433\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0413 - accuracy: 0.8344\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0430 - accuracy: 0.8433\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.0258 - accuracy: 0.8433\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0056 - accuracy: 0.8543\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9963 - accuracy: 0.8499\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9750 - accuracy: 0.8543\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9587 - accuracy: 0.8609\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.9463 - accuracy: 0.8698\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.9384 - accuracy: 0.8653\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9259 - accuracy: 0.8698\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9153 - accuracy: 0.8720\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9020 - accuracy: 0.8720\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8913 - accuracy: 0.8720\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8838 - accuracy: 0.8742\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8750 - accuracy: 0.8808\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.8647 - accuracy: 0.8742\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8560 - accuracy: 0.8808\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8481 - accuracy: 0.8874\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8376 - accuracy: 0.8830\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8303 - accuracy: 0.8830\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8240 - accuracy: 0.8808\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.8175 - accuracy: 0.8896\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8069 - accuracy: 0.8940\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7992 - accuracy: 0.8918\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7904 - accuracy: 0.8985\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7835 - accuracy: 0.9029\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7761 - accuracy: 0.9029\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7685 - accuracy: 0.9007\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7609 - accuracy: 0.9029\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7533 - accuracy: 0.9073\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7473 - accuracy: 0.9007\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7390 - accuracy: 0.9073\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.7345 - accuracy: 0.9073\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.7264 - accuracy: 0.9073\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7204 - accuracy: 0.9073\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7123 - accuracy: 0.9073\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7062 - accuracy: 0.9095\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6987 - accuracy: 0.9161\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.9161\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6852 - accuracy: 0.9139\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6818 - accuracy: 0.9095\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6748 - accuracy: 0.9161\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6669 - accuracy: 0.9205\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6610 - accuracy: 0.9161\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6542 - accuracy: 0.9139\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6488 - accuracy: 0.9205\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6431 - accuracy: 0.9205\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6370 - accuracy: 0.9227\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6301 - accuracy: 0.9227\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.9227\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6213 - accuracy: 0.9183\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6166 - accuracy: 0.9205\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6108 - accuracy: 0.9205\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6069 - accuracy: 0.9205\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6058 - accuracy: 0.9205\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6057 - accuracy: 0.9249\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5976 - accuracy: 0.9205\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6123 - accuracy: 0.9117\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6485 - accuracy: 0.9117\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6774 - accuracy: 0.8940\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.9029\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.9183\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6016 - accuracy: 0.9161\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5836 - accuracy: 0.9183\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6110 - accuracy: 0.9161\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6290 - accuracy: 0.9051\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6333 - accuracy: 0.9073\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.9073\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6014 - accuracy: 0.9139\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5884 - accuracy: 0.9051\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5641 - accuracy: 0.9183\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5452 - accuracy: 0.9161\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5367 - accuracy: 0.9205\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.5348 - accuracy: 0.9205\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5256 - accuracy: 0.9272\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5185 - accuracy: 0.9272\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5110 - accuracy: 0.9272\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.5033 - accuracy: 0.9249\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4991 - accuracy: 0.9294\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.9272\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4923 - accuracy: 0.9316\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4910 - accuracy: 0.9272\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4874 - accuracy: 0.9227\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4806 - accuracy: 0.9272\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4741 - accuracy: 0.9316\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4693 - accuracy: 0.9360\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4641 - accuracy: 0.9360\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4616 - accuracy: 0.9316\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4591 - accuracy: 0.9338\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4543 - accuracy: 0.9360\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4518 - accuracy: 0.9360\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4481 - accuracy: 0.9382\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4439 - accuracy: 0.9360\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4385 - accuracy: 0.9382\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4355 - accuracy: 0.9382\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4319 - accuracy: 0.9360\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4278 - accuracy: 0.9338\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4243 - accuracy: 0.9382\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4208 - accuracy: 0.9404\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4183 - accuracy: 0.9360\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4153 - accuracy: 0.9360\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4112 - accuracy: 0.9382\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4083 - accuracy: 0.9338\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4041 - accuracy: 0.9338\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.9338\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3983 - accuracy: 0.9338\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.9316\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3944 - accuracy: 0.9360\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.9404\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3868 - accuracy: 0.9382\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3844 - accuracy: 0.9382\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3809 - accuracy: 0.9360\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3791 - accuracy: 0.9338\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3747 - accuracy: 0.9382\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3719 - accuracy: 0.9382\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3723 - accuracy: 0.9382\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3720 - accuracy: 0.9404\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3680 - accuracy: 0.9404\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3652 - accuracy: 0.9382\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3614 - accuracy: 0.9338\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.9404\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3553 - accuracy: 0.9426\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3518 - accuracy: 0.9404\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3491 - accuracy: 0.9404\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3455 - accuracy: 0.9404\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3429 - accuracy: 0.9426\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3406 - accuracy: 0.9404\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3390 - accuracy: 0.9360\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3371 - accuracy: 0.9404\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3347 - accuracy: 0.9404\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3317 - accuracy: 0.9426\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3306 - accuracy: 0.9470\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3270 - accuracy: 0.9448\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3252 - accuracy: 0.9382\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3236 - accuracy: 0.9426\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3251 - accuracy: 0.9404\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3253 - accuracy: 0.9448\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3205 - accuracy: 0.9470\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3192 - accuracy: 0.9426\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3173 - accuracy: 0.9448\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3131 - accuracy: 0.9448\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3070 - accuracy: 0.9426\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3034 - accuracy: 0.9492\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.9470\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2988 - accuracy: 0.9448\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2972 - accuracy: 0.9470\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2951 - accuracy: 0.9470\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2924 - accuracy: 0.9448\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2902 - accuracy: 0.9470\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2884 - accuracy: 0.9470\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2879 - accuracy: 0.9448\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2851 - accuracy: 0.9514\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2829 - accuracy: 0.9492\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2816 - accuracy: 0.9470\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2793 - accuracy: 0.9492\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2781 - accuracy: 0.9492\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2788 - accuracy: 0.9536\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2764 - accuracy: 0.9514\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2739 - accuracy: 0.9492\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2731 - accuracy: 0.9470\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2849 - accuracy: 0.9426\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2714 - accuracy: 0.9492\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2685 - accuracy: 0.9492\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2652 - accuracy: 0.9536\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2620 - accuracy: 0.9536\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2615 - accuracy: 0.9448\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2588 - accuracy: 0.9492\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2587 - accuracy: 0.9470\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2569 - accuracy: 0.9536\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2554 - accuracy: 0.9492\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2536 - accuracy: 0.9448\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2507 - accuracy: 0.9536\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2492 - accuracy: 0.9536\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2480 - accuracy: 0.9536\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2461 - accuracy: 0.9448\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2470 - accuracy: 0.9492\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2473 - accuracy: 0.9470\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2440 - accuracy: 0.9492\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2442 - accuracy: 0.9492\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2414 - accuracy: 0.9514\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2414 - accuracy: 0.9492\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2391 - accuracy: 0.9514\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2401 - accuracy: 0.9470\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2678 - accuracy: 0.9382\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2736 - accuracy: 0.9404\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2793 - accuracy: 0.9448\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2748 - accuracy: 0.9448\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2872 - accuracy: 0.9382\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2768 - accuracy: 0.9382\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2843 - accuracy: 0.9426\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2837 - accuracy: 0.9448\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2903 - accuracy: 0.9360\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2701 - accuracy: 0.9448\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2505 - accuracy: 0.9536\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2455 - accuracy: 0.9470\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2413 - accuracy: 0.9448\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2383 - accuracy: 0.9470\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.9448\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2329 - accuracy: 0.9492\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2303 - accuracy: 0.9404\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2246 - accuracy: 0.9514\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2213 - accuracy: 0.9426\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2167 - accuracy: 0.9470\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2147 - accuracy: 0.9492\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2123 - accuracy: 0.9514\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2132 - accuracy: 0.9492\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2123 - accuracy: 0.9404\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2092 - accuracy: 0.9492\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2074 - accuracy: 0.9492\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2053 - accuracy: 0.9470\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2042 - accuracy: 0.9514\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2037 - accuracy: 0.9492\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2026 - accuracy: 0.9514\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1999 - accuracy: 0.9514\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1984 - accuracy: 0.9492\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2019 - accuracy: 0.9492\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2018 - accuracy: 0.9470\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1992 - accuracy: 0.9448\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1969 - accuracy: 0.9470\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1953 - accuracy: 0.9514\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1932 - accuracy: 0.9470\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1920 - accuracy: 0.9514\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1902 - accuracy: 0.9514\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1902 - accuracy: 0.9470\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1903 - accuracy: 0.9492\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1894 - accuracy: 0.9470\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1878 - accuracy: 0.9536\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1874 - accuracy: 0.9492\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1864 - accuracy: 0.9536\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1858 - accuracy: 0.9536\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1850 - accuracy: 0.9426\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1830 - accuracy: 0.9492\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1845 - accuracy: 0.9470\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1818 - accuracy: 0.9514\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1810 - accuracy: 0.9492\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1799 - accuracy: 0.9470\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1793 - accuracy: 0.9514\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1788 - accuracy: 0.9514\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1783 - accuracy: 0.9470\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1768 - accuracy: 0.9470\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1760 - accuracy: 0.9470\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1750 - accuracy: 0.9470\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1746 - accuracy: 0.9470\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1734 - accuracy: 0.9470\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1730 - accuracy: 0.9470\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1722 - accuracy: 0.9492\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1723 - accuracy: 0.9492\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1706 - accuracy: 0.9492\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1709 - accuracy: 0.9492\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1699 - accuracy: 0.9514\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9536\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1695 - accuracy: 0.9492\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1681 - accuracy: 0.9426\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1668 - accuracy: 0.9492\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1663 - accuracy: 0.9514\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1650 - accuracy: 0.9514\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1647 - accuracy: 0.9492\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1640 - accuracy: 0.9470\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1629 - accuracy: 0.9492\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1631 - accuracy: 0.9470\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1639 - accuracy: 0.9536\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1624 - accuracy: 0.9536\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.9470\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1639 - accuracy: 0.9492\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1625 - accuracy: 0.9536\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1622 - accuracy: 0.9492\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1618 - accuracy: 0.9492\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1599 - accuracy: 0.9470\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.1594 - accuracy: 0.9448\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1583 - accuracy: 0.9470\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1575 - accuracy: 0.9426\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9470\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1560 - accuracy: 0.9492\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1549 - accuracy: 0.9514\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1549 - accuracy: 0.9514\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1536 - accuracy: 0.9514\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1531 - accuracy: 0.9536\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1526 - accuracy: 0.9448\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1520 - accuracy: 0.9470\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9426\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1513 - accuracy: 0.9448\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1514 - accuracy: 0.9492\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1515 - accuracy: 0.9448\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1502 - accuracy: 0.9426\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9492\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 0.9470\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1496 - accuracy: 0.9492\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1488 - accuracy: 0.9448\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1485 - accuracy: 0.9426\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1484 - accuracy: 0.9470\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1477 - accuracy: 0.9470\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.9514\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1458 - accuracy: 0.9492\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1454 - accuracy: 0.9492\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1457 - accuracy: 0.9448\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1453 - accuracy: 0.9470\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1435 - accuracy: 0.9514\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1450 - accuracy: 0.9492\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1441 - accuracy: 0.9470\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1433 - accuracy: 0.9492\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1431 - accuracy: 0.9470\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1421 - accuracy: 0.9492\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9492\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.9492\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1408 - accuracy: 0.9426\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9514\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1407 - accuracy: 0.9448\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1402 - accuracy: 0.9470\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1395 - accuracy: 0.9492\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1392 - accuracy: 0.9492\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9470\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1401 - accuracy: 0.9492\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1445 - accuracy: 0.9470\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.9492\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1441 - accuracy: 0.9448\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1396 - accuracy: 0.9404\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1392 - accuracy: 0.9536\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1669 - accuracy: 0.9492\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2128 - accuracy: 0.9316\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2323 - accuracy: 0.9316\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1936 - accuracy: 0.9426\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2313 - accuracy: 0.9338\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1885 - accuracy: 0.9426\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1962 - accuracy: 0.9404\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1735 - accuracy: 0.9404\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1656 - accuracy: 0.9492\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1582 - accuracy: 0.9492\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9470\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1517 - accuracy: 0.9514\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 0.9492\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9448\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1514 - accuracy: 0.9448\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1494 - accuracy: 0.9426\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1475 - accuracy: 0.9426\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1489 - accuracy: 0.9492\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1453 - accuracy: 0.9514\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1429 - accuracy: 0.9404\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.9492\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1398 - accuracy: 0.9448\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1407 - accuracy: 0.9448\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1390 - accuracy: 0.9426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poeprYK8h-c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "93b03583-3d5e-416a-a428-a0b0f77d360d"
      },
      "source": [
        "plot_graphs(history, 'accuracy')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98dKkhtueYRC",
        "outputId": "e9a95d25-6b5a-4351-98dd-3289bb5b30a7"
      },
      "source": [
        "print(tokenizer.word_index.items())\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  print(word)\n",
        "  print(index)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('and', 1), ('the', 2), ('a', 3), ('in', 4), ('all', 5), ('i', 6), ('for', 7), ('of', 8), ('lanigans', 9), ('ball', 10), ('were', 11), ('at', 12), ('to', 13), ('she', 14), ('stepped', 15), ('his', 16), ('girls', 17), ('as', 18), ('they', 19), ('til', 20), ('he', 21), ('again', 22), ('got', 23), ('boys', 24), ('round', 25), ('that', 26), ('her', 27), ('there', 28), ('three', 29), ('weeks', 30), ('up', 31), ('out', 32), ('him', 33), ('was', 34), ('spent', 35), ('learning', 36), ('new', 37), ('steps', 38), ('long', 39), ('away', 40), ('left', 41), ('friends', 42), ('relations', 43), ('when', 44), ('wall', 45), ('myself', 46), ('nice', 47), ('just', 48), ('dancing', 49), ('merry', 50), ('tipped', 51), ('me', 52), ('soon', 53), ('time', 54), ('old', 55), ('their', 56), ('them', 57), ('danced', 58), ('dublin', 59), ('an', 60), ('put', 61), ('leg', 62), ('miss', 63), ('fainted', 64), ('from', 65), ('town', 66), ('athy', 67), ('one', 68), ('jeremy', 69), ('lanigan', 70), ('battered', 71), ('hadnt', 72), ('pound', 73), ('father', 74), ('died', 75), ('made', 76), ('man', 77), ('farm', 78), ('ten', 79), ('acres', 80), ('ground', 81), ('gave', 82), ('grand', 83), ('party', 84), ('who', 85), ('didnt', 86), ('forget', 87), ('come', 88), ('if', 89), ('youll', 90), ('but', 91), ('listen', 92), ('ill', 93), ('make', 94), ('your', 95), ('eyes', 96), ('glisten', 97), ('rows', 98), ('ructions', 99), ('be', 100), ('sure', 101), ('free', 102), ('invitation', 103), ('might', 104), ('ask', 105), ('minute', 106), ('both', 107), ('bees', 108), ('cask', 109), ('judy', 110), ('odaly', 111), ('little', 112), ('milliner', 113), ('wink', 114), ('give', 115), ('call', 116), ('arrived', 117), ('with', 118), ('peggy', 119), ('mcgilligan', 120), ('lashings', 121), ('punch', 122), ('wine', 123), ('ladies', 124), ('potatoes', 125), ('cakes', 126), ('bacon', 127), ('tea', 128), ('nolans', 129), ('dolans', 130), ('ogradys', 131), ('courting', 132), ('songs', 133), ('went', 134), ('plenty', 135), ('water', 136), ('harp', 137), ('once', 138), ('sounded', 139), ('taras', 140), ('hall', 141), ('sweet', 142), ('nelly', 143), ('gray', 144), ('rat', 145), ('catchers', 146), ('daughter', 147), ('singing', 148), ('together', 149), ('doing', 150), ('kinds', 151), ('nonsensical', 152), ('polkas', 153), ('room', 154), ('whirligig', 155), ('julia', 156), ('we', 157), ('banished', 158), ('nonsense', 159), ('twist', 160), ('reel', 161), ('jig', 162), ('ach', 163), ('mavrone', 164), ('how', 165), ('mad', 166), ('youd', 167), ('think', 168), ('ceiling', 169), ('would', 170), ('fall', 171), ('brooks', 172), ('academy', 173), ('learn', 174), ('nothing', 175), ('hearty', 176), ('around', 177), ('couples', 178), ('groups', 179), ('accident', 180), ('happened', 181), ('young', 182), ('terrance', 183), ('mccarthy', 184), ('right', 185), ('through', 186), ('finnertys', 187), ('hoops', 188), ('poor', 189), ('creature', 190), ('cried', 191), ('meelia', 192), ('murther', 193), ('called', 194), ('brothers', 195), ('gathered', 196), ('carmody', 197), ('swore', 198), ('hed', 199), ('go', 200), ('no', 201), ('further', 202), ('had', 203), ('satisfaction', 204), ('midst', 205), ('row', 206), ('kerrigan', 207), ('cheeks', 208), ('same', 209), ('red', 210), ('rose', 211), ('some', 212), ('lads', 213), ('declared', 214), ('painted', 215), ('took', 216), ('small', 217), ('drop', 218), ('too', 219), ('much', 220), ('suppose', 221), ('sweetheart', 222), ('ned', 223), ('morgan', 224), ('so', 225), ('powerful', 226), ('able', 227), ('saw', 228), ('fair', 229), ('colleen', 230), ('stretched', 231), ('by', 232), ('tore', 233), ('under', 234), ('table', 235), ('smashed', 236), ('chaneys', 237), ('oh', 238), ('twas', 239), ('then', 240), ('runctions', 241), ('lick', 242), ('big', 243), ('phelim', 244), ('mchugh', 245), ('replied', 246), ('introduction', 247), ('kicked', 248), ('terrible', 249), ('hullabaloo', 250), ('casey', 251), ('piper', 252), ('near', 253), ('being', 254), ('strangled', 255), ('squeezed', 256), ('pipes', 257), ('bellows', 258), ('chanters', 259), ('ribbons', 260), ('entangled', 261), ('end', 262)])\n",
            "and\n",
            "1\n",
            "the\n",
            "2\n",
            "a\n",
            "3\n",
            "in\n",
            "4\n",
            "all\n",
            "5\n",
            "i\n",
            "6\n",
            "for\n",
            "7\n",
            "of\n",
            "8\n",
            "lanigans\n",
            "9\n",
            "ball\n",
            "10\n",
            "were\n",
            "11\n",
            "at\n",
            "12\n",
            "to\n",
            "13\n",
            "she\n",
            "14\n",
            "stepped\n",
            "15\n",
            "his\n",
            "16\n",
            "girls\n",
            "17\n",
            "as\n",
            "18\n",
            "they\n",
            "19\n",
            "til\n",
            "20\n",
            "he\n",
            "21\n",
            "again\n",
            "22\n",
            "got\n",
            "23\n",
            "boys\n",
            "24\n",
            "round\n",
            "25\n",
            "that\n",
            "26\n",
            "her\n",
            "27\n",
            "there\n",
            "28\n",
            "three\n",
            "29\n",
            "weeks\n",
            "30\n",
            "up\n",
            "31\n",
            "out\n",
            "32\n",
            "him\n",
            "33\n",
            "was\n",
            "34\n",
            "spent\n",
            "35\n",
            "learning\n",
            "36\n",
            "new\n",
            "37\n",
            "steps\n",
            "38\n",
            "long\n",
            "39\n",
            "away\n",
            "40\n",
            "left\n",
            "41\n",
            "friends\n",
            "42\n",
            "relations\n",
            "43\n",
            "when\n",
            "44\n",
            "wall\n",
            "45\n",
            "myself\n",
            "46\n",
            "nice\n",
            "47\n",
            "just\n",
            "48\n",
            "dancing\n",
            "49\n",
            "merry\n",
            "50\n",
            "tipped\n",
            "51\n",
            "me\n",
            "52\n",
            "soon\n",
            "53\n",
            "time\n",
            "54\n",
            "old\n",
            "55\n",
            "their\n",
            "56\n",
            "them\n",
            "57\n",
            "danced\n",
            "58\n",
            "dublin\n",
            "59\n",
            "an\n",
            "60\n",
            "put\n",
            "61\n",
            "leg\n",
            "62\n",
            "miss\n",
            "63\n",
            "fainted\n",
            "64\n",
            "from\n",
            "65\n",
            "town\n",
            "66\n",
            "athy\n",
            "67\n",
            "one\n",
            "68\n",
            "jeremy\n",
            "69\n",
            "lanigan\n",
            "70\n",
            "battered\n",
            "71\n",
            "hadnt\n",
            "72\n",
            "pound\n",
            "73\n",
            "father\n",
            "74\n",
            "died\n",
            "75\n",
            "made\n",
            "76\n",
            "man\n",
            "77\n",
            "farm\n",
            "78\n",
            "ten\n",
            "79\n",
            "acres\n",
            "80\n",
            "ground\n",
            "81\n",
            "gave\n",
            "82\n",
            "grand\n",
            "83\n",
            "party\n",
            "84\n",
            "who\n",
            "85\n",
            "didnt\n",
            "86\n",
            "forget\n",
            "87\n",
            "come\n",
            "88\n",
            "if\n",
            "89\n",
            "youll\n",
            "90\n",
            "but\n",
            "91\n",
            "listen\n",
            "92\n",
            "ill\n",
            "93\n",
            "make\n",
            "94\n",
            "your\n",
            "95\n",
            "eyes\n",
            "96\n",
            "glisten\n",
            "97\n",
            "rows\n",
            "98\n",
            "ructions\n",
            "99\n",
            "be\n",
            "100\n",
            "sure\n",
            "101\n",
            "free\n",
            "102\n",
            "invitation\n",
            "103\n",
            "might\n",
            "104\n",
            "ask\n",
            "105\n",
            "minute\n",
            "106\n",
            "both\n",
            "107\n",
            "bees\n",
            "108\n",
            "cask\n",
            "109\n",
            "judy\n",
            "110\n",
            "odaly\n",
            "111\n",
            "little\n",
            "112\n",
            "milliner\n",
            "113\n",
            "wink\n",
            "114\n",
            "give\n",
            "115\n",
            "call\n",
            "116\n",
            "arrived\n",
            "117\n",
            "with\n",
            "118\n",
            "peggy\n",
            "119\n",
            "mcgilligan\n",
            "120\n",
            "lashings\n",
            "121\n",
            "punch\n",
            "122\n",
            "wine\n",
            "123\n",
            "ladies\n",
            "124\n",
            "potatoes\n",
            "125\n",
            "cakes\n",
            "126\n",
            "bacon\n",
            "127\n",
            "tea\n",
            "128\n",
            "nolans\n",
            "129\n",
            "dolans\n",
            "130\n",
            "ogradys\n",
            "131\n",
            "courting\n",
            "132\n",
            "songs\n",
            "133\n",
            "went\n",
            "134\n",
            "plenty\n",
            "135\n",
            "water\n",
            "136\n",
            "harp\n",
            "137\n",
            "once\n",
            "138\n",
            "sounded\n",
            "139\n",
            "taras\n",
            "140\n",
            "hall\n",
            "141\n",
            "sweet\n",
            "142\n",
            "nelly\n",
            "143\n",
            "gray\n",
            "144\n",
            "rat\n",
            "145\n",
            "catchers\n",
            "146\n",
            "daughter\n",
            "147\n",
            "singing\n",
            "148\n",
            "together\n",
            "149\n",
            "doing\n",
            "150\n",
            "kinds\n",
            "151\n",
            "nonsensical\n",
            "152\n",
            "polkas\n",
            "153\n",
            "room\n",
            "154\n",
            "whirligig\n",
            "155\n",
            "julia\n",
            "156\n",
            "we\n",
            "157\n",
            "banished\n",
            "158\n",
            "nonsense\n",
            "159\n",
            "twist\n",
            "160\n",
            "reel\n",
            "161\n",
            "jig\n",
            "162\n",
            "ach\n",
            "163\n",
            "mavrone\n",
            "164\n",
            "how\n",
            "165\n",
            "mad\n",
            "166\n",
            "youd\n",
            "167\n",
            "think\n",
            "168\n",
            "ceiling\n",
            "169\n",
            "would\n",
            "170\n",
            "fall\n",
            "171\n",
            "brooks\n",
            "172\n",
            "academy\n",
            "173\n",
            "learn\n",
            "174\n",
            "nothing\n",
            "175\n",
            "hearty\n",
            "176\n",
            "around\n",
            "177\n",
            "couples\n",
            "178\n",
            "groups\n",
            "179\n",
            "accident\n",
            "180\n",
            "happened\n",
            "181\n",
            "young\n",
            "182\n",
            "terrance\n",
            "183\n",
            "mccarthy\n",
            "184\n",
            "right\n",
            "185\n",
            "through\n",
            "186\n",
            "finnertys\n",
            "187\n",
            "hoops\n",
            "188\n",
            "poor\n",
            "189\n",
            "creature\n",
            "190\n",
            "cried\n",
            "191\n",
            "meelia\n",
            "192\n",
            "murther\n",
            "193\n",
            "called\n",
            "194\n",
            "brothers\n",
            "195\n",
            "gathered\n",
            "196\n",
            "carmody\n",
            "197\n",
            "swore\n",
            "198\n",
            "hed\n",
            "199\n",
            "go\n",
            "200\n",
            "no\n",
            "201\n",
            "further\n",
            "202\n",
            "had\n",
            "203\n",
            "satisfaction\n",
            "204\n",
            "midst\n",
            "205\n",
            "row\n",
            "206\n",
            "kerrigan\n",
            "207\n",
            "cheeks\n",
            "208\n",
            "same\n",
            "209\n",
            "red\n",
            "210\n",
            "rose\n",
            "211\n",
            "some\n",
            "212\n",
            "lads\n",
            "213\n",
            "declared\n",
            "214\n",
            "painted\n",
            "215\n",
            "took\n",
            "216\n",
            "small\n",
            "217\n",
            "drop\n",
            "218\n",
            "too\n",
            "219\n",
            "much\n",
            "220\n",
            "suppose\n",
            "221\n",
            "sweetheart\n",
            "222\n",
            "ned\n",
            "223\n",
            "morgan\n",
            "224\n",
            "so\n",
            "225\n",
            "powerful\n",
            "226\n",
            "able\n",
            "227\n",
            "saw\n",
            "228\n",
            "fair\n",
            "229\n",
            "colleen\n",
            "230\n",
            "stretched\n",
            "231\n",
            "by\n",
            "232\n",
            "tore\n",
            "233\n",
            "under\n",
            "234\n",
            "table\n",
            "235\n",
            "smashed\n",
            "236\n",
            "chaneys\n",
            "237\n",
            "oh\n",
            "238\n",
            "twas\n",
            "239\n",
            "then\n",
            "240\n",
            "runctions\n",
            "241\n",
            "lick\n",
            "242\n",
            "big\n",
            "243\n",
            "phelim\n",
            "244\n",
            "mchugh\n",
            "245\n",
            "replied\n",
            "246\n",
            "introduction\n",
            "247\n",
            "kicked\n",
            "248\n",
            "terrible\n",
            "249\n",
            "hullabaloo\n",
            "250\n",
            "casey\n",
            "251\n",
            "piper\n",
            "252\n",
            "near\n",
            "253\n",
            "being\n",
            "254\n",
            "strangled\n",
            "255\n",
            "squeezed\n",
            "256\n",
            "pipes\n",
            "257\n",
            "bellows\n",
            "258\n",
            "chanters\n",
            "259\n",
            "ribbons\n",
            "260\n",
            "entangled\n",
            "261\n",
            "end\n",
            "262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47957027-057d-4f26-92d5-c7dd72441ad4"
      },
      "source": [
        "seed_text = \"Laurence went to dublin\"\n",
        "next_words = 10\n",
        "\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tfor i in predicted:\n",
        "\t\t\tif index == i.any:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laurence went to dublin          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBCvyFXtgGDg"
      },
      "source": [
        "??????? 웨 않되?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSyop7j-gE3h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g2vLjTUhgjT"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dC8yyDXhgjT"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}